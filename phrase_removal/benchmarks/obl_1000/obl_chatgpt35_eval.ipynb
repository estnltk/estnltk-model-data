{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95aa9887-5001-4c32-bc7b-ec4820972365",
   "metadata": {},
   "source": [
    "# Anaphor resolution with ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d1180d-545c-4526-8978-42a1c7c7a667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaire/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "import configparser\n",
    "\n",
    "from pandas import read_excel\n",
    "from pandas import DataFrame\n",
    "from tqdm.auto import tqdm \n",
    "from math import isnan\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9685c-b13e-4ea5-938d-45b4d026daad",
   "metadata": {},
   "source": [
    "## I. Set up Azure API : openai ver 1.35.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26dd33c7-07cb-4144-bae5-f052f8c2fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "status = config.read('azure.ini') \n",
    "assert status == ['azure.ini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a392a60-56b7-443b-849f-b760d9b2f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOIMENT_ID = config['azure-configuration']['deployment_id']\n",
    "GPT_MODEL = config['azure-configuration']['model']\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = config['azure-configuration']['api_key'],\n",
    "  api_version = config['azure-configuration']['api_version'],\n",
    "  azure_endpoint = config['azure-configuration']['api_base'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1f24fc-ae0d-40c6-80ed-8622e794fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(prompt: str) -> str:\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = DEPLOIMENT_ID,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'FAIL'\n",
    "    return response.choices[0].message.content   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5abe63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples = pd.read_csv(\"obl_gpt_input_large1.csv\", sep=';', encoding='utf-8')\n",
    "#testsamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5164508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Is the following Estonian sentence delimited by triple backticks grammatically correct: ```{sentence}```\\n\" \n",
    "    'Ignore punctuation and capitalization. Answer “yes” or “no\".'\n",
    ")\n",
    "\n",
    "answers = []\n",
    "for i in range(len(testsamples)):\n",
    "    sent = testsamples.iloc[i][\"short_sent\"]\n",
    "    answ = ask_openai(prompt.format(sentence=sent))\n",
    "    if len(answ)>3:\n",
    "        answ = answ[:3]\n",
    "    answ = answ.replace(\",\", \"\").strip().lower()  \n",
    "    answ = answ.replace(\".\", \"\").strip().lower()  \n",
    "    answers.append(answ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "005ea742",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples['gpt'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff316f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.    0.532 0.541]\n",
      "recall: [0.    0.578 0.492]\n",
      "fscore: [0.    0.554 0.515]\n",
      "support: [  0 500 500]\n",
      "precision:  0.541\n",
      "recall:  0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaire/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = list(testsamples['gpt'])\n",
    "y_test = list(testsamples['removetype'])\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted)\n",
    "\n",
    "print('precision: {}'.format(precision.round(3)))\n",
    "print('recall: {}'.format(recall.round(3)))\n",
    "print('fscore: {}'.format(fscore.round(3)))\n",
    "print('support: {}'.format(support.round(3)))\n",
    "\n",
    "try:\n",
    "    precision = precision_score(y_test, predicted, pos_label='yes', average='binary')\n",
    "    recall = recall_score(y_test, predicted, pos_label='yes', average='binary')\n",
    "except:\n",
    "    precision = precision_score(y_test, predicted, labels=['yes'], average='micro')\n",
    "    recall = recall_score(y_test, predicted, labels=['yes'], average='micro')\n",
    "print('precision: ',precision.round(3))\n",
    "print('recall: ',recall.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69f06a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples[\"match\"] = testsamples.removetype.eq(testsamples.gpt) # true if annotation and prediction are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13dd1a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match\n",
       "True     535\n",
       "False    465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsamples.value_counts(\"match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8982b327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt\n",
       "no     543\n",
       "yes    455\n",
       "fai      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsamples.value_counts(\"gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b75910b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples.to_csv(\"obl_gpt_input_large1_answers.csv\", index= False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2966d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cd6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d05e3b6",
   "metadata": {},
   "source": [
    "### Also test on untokenized sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a647807",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fpath</th>\n",
       "      <th>sentence</th>\n",
       "      <th>remove_start</th>\n",
       "      <th>remove_end</th>\n",
       "      <th>removed</th>\n",
       "      <th>type</th>\n",
       "      <th>short_sent</th>\n",
       "      <th>cons_score</th>\n",
       "      <th>ual</th>\n",
       "      <th>la</th>\n",
       "      <th>removetype</th>\n",
       "      <th>short_sent_untoken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1051</td>\n",
       "      <td>Train/tea_eesti_arst_2004_osa_3_ud211.conllu</td>\n",
       "      <td>Seda ka kohe-kohe algavatel järjekordsetel pal...</td>\n",
       "      <td>107</td>\n",
       "      <td>127</td>\n",
       "      <td>peale haiglate liidu</td>\n",
       "      <td>free</td>\n",
       "      <td>Seda ka kohe-kohe algavatel järjekordsetel pal...</td>\n",
       "      <td>58.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>82.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>Seda ka kohe-kohe algavatel järjekordsetel pal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1389</td>\n",
       "      <td>Train/aja_luup200106_osa_2_ud211.conllu</td>\n",
       "      <td>Kuna eestlased hindavad oma kodu kõrgelt , sii...</td>\n",
       "      <td>204</td>\n",
       "      <td>215</td>\n",
       "      <td>elamispinda</td>\n",
       "      <td>free</td>\n",
       "      <td>Kuna eestlased hindavad oma kodu kõrgelt , sii...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>Kuna eestlased hindavad oma kodu kõrgelt, siis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1109</td>\n",
       "      <td>Train/aja_pm20000218_osa_5_ud211.conllu</td>\n",
       "      <td>Järgnevalt anti Marsile kiiresti mitu käsku , ...</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>Marsile</td>\n",
       "      <td>free</td>\n",
       "      <td>Järgnevalt anti kiiresti mitu käsku , lootuses...</td>\n",
       "      <td>86.7</td>\n",
       "      <td>86.7</td>\n",
       "      <td>96.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>Järgnevalt anti kiiresti mitu käsku, lootuses,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>398</td>\n",
       "      <td>Train/aja_luup200202_osa_1_ud211.conllu</td>\n",
       "      <td>Enne minekut hoiatab ta oma leebel moel , et ä...</td>\n",
       "      <td>59</td>\n",
       "      <td>66</td>\n",
       "      <td>haiglas</td>\n",
       "      <td>free</td>\n",
       "      <td>Enne minekut hoiatab ta oma leebel moel , et ä...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Enne minekut hoiatab ta oma leebel moel, et är...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2346</td>\n",
       "      <td>Train/arborest_ud211.conllu</td>\n",
       "      <td>Peeter kargas läbi akna aeda kuue järele .</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>aeda</td>\n",
       "      <td>free</td>\n",
       "      <td>Peeter kargas läbi akna kuue järele .</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>Peeter kargas läbi akna kuue järele.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                         fpath  \\\n",
       "0  1051  Train/tea_eesti_arst_2004_osa_3_ud211.conllu   \n",
       "1  1389       Train/aja_luup200106_osa_2_ud211.conllu   \n",
       "2  1109       Train/aja_pm20000218_osa_5_ud211.conllu   \n",
       "3   398       Train/aja_luup200202_osa_1_ud211.conllu   \n",
       "4  2346                   Train/arborest_ud211.conllu   \n",
       "\n",
       "                                            sentence  remove_start  \\\n",
       "0  Seda ka kohe-kohe algavatel järjekordsetel pal...           107   \n",
       "1  Kuna eestlased hindavad oma kodu kõrgelt , sii...           204   \n",
       "2  Järgnevalt anti Marsile kiiresti mitu käsku , ...            16   \n",
       "3  Enne minekut hoiatab ta oma leebel moel , et ä...            59   \n",
       "4         Peeter kargas läbi akna aeda kuue järele .            24   \n",
       "\n",
       "   remove_end               removed  type  \\\n",
       "0         127  peale haiglate liidu  free   \n",
       "1         215           elamispinda  free   \n",
       "2          23               Marsile  free   \n",
       "3          66               haiglas  free   \n",
       "4          28                  aeda  free   \n",
       "\n",
       "                                          short_sent  cons_score    ual  \\\n",
       "0  Seda ka kohe-kohe algavatel järjekordsetel pal...        58.8   64.7   \n",
       "1  Kuna eestlased hindavad oma kodu kõrgelt , sii...        20.0   23.3   \n",
       "2  Järgnevalt anti kiiresti mitu käsku , lootuses...        86.7   86.7   \n",
       "3  Enne minekut hoiatab ta oma leebel moel , et ä...       100.0  100.0   \n",
       "4              Peeter kargas läbi akna kuue järele .       100.0  100.0   \n",
       "\n",
       "      la removetype                                 short_sent_untoken  \n",
       "0   82.4        yes  Seda ka kohe-kohe algavatel järjekordsetel pal...  \n",
       "1   33.3        yes  Kuna eestlased hindavad oma kodu kõrgelt, siis...  \n",
       "2   96.7        yes  Järgnevalt anti kiiresti mitu käsku, lootuses,...  \n",
       "3  100.0        yes  Enne minekut hoiatab ta oma leebel moel, et är...  \n",
       "4  100.0        yes               Peeter kargas läbi akna kuue järele.  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsamples = pd.read_csv(\"obl_gpt_input_large1.csv\", sep=';', encoding='utf-8')\n",
    "testsamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52a9697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': True, 'severity': 'medium'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"Is the following Estonian sentence delimited by triple backticks grammatically correct: ```{sentence}```\\n\" \n",
    "    'Ignore punctuation and capitalization. Answer “yes” or “no\".'\n",
    ")\n",
    "\n",
    "answers = []\n",
    "for i in range(len(testsamples)):\n",
    "    sent = testsamples.iloc[i][\"short_sent_untoken\"]\n",
    "    answ = ask_openai(prompt.format(sentence=sent))\n",
    "    if len(answ)>3:\n",
    "        answ = answ[:3]\n",
    "    answ = answ.replace(\",\", \"\").strip().lower()  \n",
    "    answ = answ.replace(\".\", \"\").strip().lower()  \n",
    "    answers.append(answ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08ad3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples['gpt'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b76dba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.    0.581 0.546]\n",
      "recall: [0.    0.408 0.706]\n",
      "fscore: [0.    0.479 0.616]\n",
      "support: [  0 500 500]\n",
      "precision:  0.546\n",
      "recall:  0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaire/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = list(testsamples['gpt'])\n",
    "y_test = list(testsamples['removetype'])\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted)\n",
    "\n",
    "print('precision: {}'.format(precision.round(3)))\n",
    "print('recall: {}'.format(recall.round(3)))\n",
    "print('fscore: {}'.format(fscore.round(3)))\n",
    "print('support: {}'.format(support.round(3)))\n",
    "\n",
    "try:\n",
    "    precision = precision_score(y_test, predicted, pos_label='yes', average='binary')\n",
    "    recall = recall_score(y_test, predicted, pos_label='yes', average='binary')\n",
    "except:\n",
    "    precision = precision_score(y_test, predicted, labels=['yes'], average='micro')\n",
    "    recall = recall_score(y_test, predicted, labels=['yes'], average='micro')\n",
    "print('precision: ',precision.round(3))\n",
    "print('recall: ',recall.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57b6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples[\"match\"] = testsamples.removetype.eq(testsamples.gpt) # true if annotation and prediction are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e08cec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match\n",
       "True     557\n",
       "False    443\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsamples.value_counts(\"match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12682874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt\n",
       "yes    647\n",
       "no     351\n",
       "fai      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsamples.value_counts(\"gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c4bd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsamples.to_csv(\"obl_gpt_input_large1_untoken_answers.csv\", index= False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61997bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
