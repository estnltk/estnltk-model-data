{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a651dd",
   "metadata": {},
   "source": [
    "# Workflow for updating the benchmark\n",
    "\n",
    "This workflow adds texts to the benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18418a9f",
   "metadata": {},
   "source": [
    "## I. Initial split  into subpopulations  \n",
    "\n",
    "The entire recall set consists of all geographic named entities for which the last word is among [the predefined suffix_words](geo_terms.txt). \n",
    "\n",
    "\n",
    "|Subpopulation     | Description | Examples |\n",
    "|:--- |:---|:---|\n",
    "|Levinumad         | Geographic locations with most frequent suffixes | Niiluse jõgi, Aasovi meri, Peipsi järv   |  \n",
    "|Mitmetäneduslikud | Geographic locations with ambigous suffixes      | Panama kanal, Panga pank, Kura kurk      |\n",
    "|Ülejäänud         | Other geographic locations                       | Vaikne ookean, Liivi laht, Tehvandi mägi |   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e432b2",
   "metadata": {},
   "source": [
    "## II. Consistency with the benchmark setup\n",
    "\n",
    "* Check that necessary recall_sets exist and are readable CSV files\n",
    "* Check that there are no invalid nor duplicate annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13867bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['levinumad', 'mitmetahenduslikud', 'ulejaanud'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_functions import load_term_subpopulations\n",
    "term_subpopulations = load_term_subpopulations()\n",
    "term_subpopulations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f8a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating 'levinumad' ...\n",
      "OK\n",
      "Validating 'mitmetahenduslikud' ...\n",
      "OK\n",
      "Validating 'ulejaanud' ...\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from pandas import read_csv\n",
    "from helper_functions import DuplicatesChecker\n",
    "checker = DuplicatesChecker()\n",
    "\n",
    "for subpopulation in term_subpopulations.keys():\n",
    "    print(f'Validating {subpopulation!r} ...')\n",
    "    filename = f'labelled_data/recall_sets/koond_1000_{subpopulation}.csv'\n",
    "    # Validate file\n",
    "    assert os.path.exists(filename), f'(!) Missing file: {filename}'\n",
    "    try:\n",
    "        data = read_csv(filename)\n",
    "    except Exception as csv_parsing_err:\n",
    "        raise ValueError(f'(!) Bad input file format: unable to open {filename!r} as a CSV file: ') from csv_parsing_er\n",
    "    # Validate file's contents \n",
    "    for txt, span in zip(data.text, data.span):\n",
    "        checker.check_for_duplicates(txt, span)\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72602ebe",
   "metadata": {},
   "source": [
    "## III. Update the benchmark data\n",
    "\n",
    "### Gather necessary counts\n",
    "\n",
    "First, we need to obtain total term counts in each subpopulation. \n",
    "This information is available in the local database file created by the SpanSampler.\n",
    "Reload the database and get the information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b63e703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:57: connecting to host: 'postgres.keeleressursid.ee', port: 5432, dbname: 'estonian-text-corpora', user: 'soras'\n",
      "INFO:storage.py:108: schema: 'estonian_text_corpora', temporary: False, role: 'estonian_text_corpora_read'\n",
      "Loaded 63 terms from geo_terms.txt.\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import load_configuration, connect_to_database\n",
    "from helper_functions import load_term_subpopulations, count_terms_by_subpopulations\n",
    "from span_sampler_sqlite3 import SpanSampler\n",
    "\n",
    "config = load_configuration('config\\example_configuration.ini')\n",
    "storage = connect_to_database(config)\n",
    "collection = config['source_database']['collection']\n",
    "collection = storage[collection]\n",
    "\n",
    "sampler = SpanSampler(collection=collection, \n",
    "                      layer=config['source_database']['terms_layer'], \n",
    "                      attribute='lemma', \n",
    "                      termsfile='geo_terms.txt', \n",
    "                      db_file_name=config['local_database']['sqlite_file'], \n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51482344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'levinumad': 84822, 'mitmetahenduslikud': 81893, 'ulejaanud': 185897}\n"
     ]
    }
   ],
   "source": [
    "# Load total counts of each subpopulation\n",
    "subpopulation_totals = \\\n",
    "    count_terms_by_subpopulations(sampler, subpopulations_dir='config/subpopulations')\n",
    "print(subpopulation_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75244d1c",
   "metadata": {},
   "source": [
    "Second, get numbers of positive cases (detected entities) for each subpopulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0174cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect numbers of positive cases\n",
    "from pandas import read_csv\n",
    "\n",
    "positives = {}\n",
    "for subpopulation in term_subpopulations.keys():\n",
    "    positives[subpopulation] = 0\n",
    "    filename = f'labelled_data/recall_sets/koond_1000_{subpopulation}.csv'\n",
    "    try:\n",
    "        data = read_csv(filename)\n",
    "    except Exception as csv_parsing_err:\n",
    "        raise ValueError(f'(!) Bad input file format: unable to open {filename!r} as a CSV file: ') from csv_parsing_err\n",
    "    positives[subpopulation] += len(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba43ac",
   "metadata": {},
   "source": [
    "### Create dataset description CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e825df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3193b8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>occurences</th>\n",
       "      <th>labelled</th>\n",
       "      <th>positive</th>\n",
       "      <th>occurence_ratio</th>\n",
       "      <th>detection_ratio</th>\n",
       "      <th>relative_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levinumad</td>\n",
       "      <td>84822</td>\n",
       "      <td>1000</td>\n",
       "      <td>350</td>\n",
       "      <td>0.240553</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.473287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mitmetahenduslikud</td>\n",
       "      <td>81893</td>\n",
       "      <td>1000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.232247</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.016972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ulejaanud</td>\n",
       "      <td>185897</td>\n",
       "      <td>1000</td>\n",
       "      <td>172</td>\n",
       "      <td>0.527200</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.509740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           population  occurences  labelled  positive  occurence_ratio  \\\n",
       "0           levinumad       84822      1000       350         0.240553   \n",
       "1  mitmetahenduslikud       81893      1000        13         0.232247   \n",
       "2           ulejaanud      185897      1000       172         0.527200   \n",
       "\n",
       "   detection_ratio  relative_frequency  \n",
       "0            0.350            0.473287  \n",
       "1            0.013            0.016972  \n",
       "2            0.172            0.509740  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add initial statistics about sub populations\n",
    "sorted_populations = sorted(term_subpopulations.keys())\n",
    "df = DataFrame({\n",
    "    'population': sorted_populations,\n",
    "    'occurences': [subpopulation_totals[s_pop] for s_pop in sorted_populations],\n",
    "    'labelled': [1000 for s_pop in sorted_populations],\n",
    "    'positive': [positives[s_pop] for s_pop in sorted_populations]\n",
    "})\n",
    "# Compute some additional statistics\n",
    "df['occurence_ratio'] = df['occurences']/sum(df['occurences'])\n",
    "df['detection_ratio'] = df['positive']/df['labelled']\n",
    "df['relative_frequency'] = df['occurence_ratio'] * df['positive']/sum(df['occurence_ratio'] * df['positive'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfce9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file names (full paths)\n",
    "df['file'] = [f'amundsen_01/data/recall_sets/koond_1000_{s_pop}.csv' for s_pop in sorted_populations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ac6f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "df.to_csv('data_description.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
