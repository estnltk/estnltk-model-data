{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e316e75",
   "metadata": {},
   "source": [
    "# Workflow for searching new recall samples\n",
    "\n",
    "Finds a random sample of potential positive samples. Converts these to labelstudio format for manual tagging. For this specific task, we create three different subsamples based on the geographic term. This is to improve the accuracy of the recall estimation by grouping samples to groups where the tagger might get different results. The groups here are: most common geographic terms, geographic terms that are homonyms of some more popular word and all the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e8cac",
   "metadata": {},
   "source": [
    "## I. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d494a28",
   "metadata": {},
   "source": [
    "### Loading the source corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a3d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:57: connecting to host: 'postgres.keeleressursid.ee', port: 5432, dbname: 'estonian-text-corpora', user: 'soras'\n",
      "INFO:storage.py:108: schema: 'estonian_text_corpora', temporary: False, role: 'estonian_text_corpora_read'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "user=soras password=xxx dbname=estonian-text-corpora host=postgres.keeleressursid.ee port=5432 schema=estonian_text_corpora<br/>temporary=False<br/>\n",
       "collection count: 5\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>total_size</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <th>version</th>\n",
       "      <th>relations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"17\" valign=\"top\">koondkorpus_base_subset_of_5000_v2</th>\n",
       "      <th rowspan=\"17\" valign=\"top\">2.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>12 MB</td>\n",
       "      <td>Collection of 5000 randomly picked Koondkorpus texts (v2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_sentences_flat__la</th>\n",
       "      <td>0</td>\n",
       "      <td>5544 kB</td>\n",
       "      <td>created by soras on Fri Jun 12 11:28:06 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>19 MB</td>\n",
       "      <td>created by soras on Fri Jun 12 09:15:46 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words_morph_analys</th>\n",
       "      <td>0</td>\n",
       "      <td>96 MB</td>\n",
       "      <td>Morphological analysis from v1.6.2/3, probably based on commit 349a7c2 (2018-11-22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_compound_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>5472 kB</td>\n",
       "      <td>created by soras on Thu Jun  4 12:29:42 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_morph_analysis__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>97 MB</td>\n",
       "      <td>created by soras on Tue Jun  9 14:13:07 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_sentences__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>21 MB</td>\n",
       "      <td>created by soras on Tue Jun  9 06:01:41 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>20 MB</td>\n",
       "      <td>created by soras on Thu Jun  4 07:40:39 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>20 MB</td>\n",
       "      <td>created by soras on Fri Jun  5 05:49:26 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_ensemble_syntax</th>\n",
       "      <td>0</td>\n",
       "      <td>95 MB</td>\n",
       "      <td>created by soras on Wed Aug  4 08:53:37 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_pos_based_synta</th>\n",
       "      <td>0</td>\n",
       "      <td>77 MB</td>\n",
       "      <td>created by soras on Wed Aug 11 17:26:41 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>95 MB</td>\n",
       "      <td>created by soras on Fri Jul  2 16:07:05 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_clauses__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>22 MB</td>\n",
       "      <td>created by soras on Mon Sep 12 11:26:29 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_named_entities__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>5624 kB</td>\n",
       "      <td>created by soras on Tue May 17 11:01:56 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>1896 kB</td>\n",
       "      <td>created by soras on Mon Jan  2 12:25:16 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_timexes__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>5704 kB</td>\n",
       "      <td>created by soras on Wed Sep 20 17:21:25 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"17\" valign=\"top\">koondkorpus_base_v2</th>\n",
       "      <th rowspan=\"17\" valign=\"top\">2.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>1618 MB</td>\n",
       "      <td>Collection of Koondkorpus texts (v2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_sentences_flat__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>740 MB</td>\n",
       "      <td>created by soras on Mon Jun 15 06:44:30 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2553 MB</td>\n",
       "      <td>created by soras on Fri Jun 12 12:25:44 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words_morph_analysis__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>13 GB</td>\n",
       "      <td>Morphological analysis from v1.6.2/3, probably based on commit 349a7c2 (2018-11-22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_compound_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>698 MB</td>\n",
       "      <td>created by soras on Thu Jun  4 12:36:01 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_morph_analysis__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>13 GB</td>\n",
       "      <td>created by soras on Tue Jun  9 14:32:08 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_sentences__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2860 MB</td>\n",
       "      <td>created by soras on Tue Jun  9 06:07:08 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2587 MB</td>\n",
       "      <td>created by soras on Thu Jun  4 07:42:49 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2622 MB</td>\n",
       "      <td>created by soras on Fri Jun  5 05:53:18 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_ensemble_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>12 GB</td>\n",
       "      <td>created by soras on Thu Aug  5 17:31:45 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_pos_based_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>10 GB</td>\n",
       "      <td>created by soras on Thu Aug 12 18:03:09 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>12 GB</td>\n",
       "      <td>created by soras on Wed Jul 28 10:45:04 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_clauses__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2884 MB</td>\n",
       "      <td>created by soras on Mon Sep 12 11:46:59 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_named_entities__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>752 MB</td>\n",
       "      <td>created by soras on Tue May 17 14:29:05 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>247 MB</td>\n",
       "      <td>created by soras on Mon Jan  2 12:30:20 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_timexes__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>779 MB</td>\n",
       "      <td>created by soras on Wed Sep 20 17:59:29 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">koondkorpus_sentences</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">3.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>82 GB</td>\n",
       "      <td>koondkorpus_base_v2 texts split into sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v171_named_entities__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>7452 MB</td>\n",
       "      <td>created by soras on Mon Dec  5 11:27:53 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_advmod_phrases__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>7416 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 14:49:31 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_clauses__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>18 GB</td>\n",
       "      <td>created by soras on Thu Jun  1 17:57:53 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>6187 MB</td>\n",
       "      <td>created by soras on Wed Jan  4 11:12:06 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_obl_phrases__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>10027 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 14:44:17 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_pre_timexes__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2100 MB</td>\n",
       "      <td>created by soras on Thu Mar 16 11:02:14 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_stanza_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>29 GB</td>\n",
       "      <td>created by soras on Thu Jan 26 15:12:12 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">koondkorpus_sentences_test_5000_sg_thread</th>\n",
       "      <th rowspan=\"9\" valign=\"top\">3.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>652 MB</td>\n",
       "      <td>5000 texts split into sentences (based on v2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v171_named_entities_</th>\n",
       "      <td>0</td>\n",
       "      <td>62 MB</td>\n",
       "      <td>created by soras on Fri Dec  2 16:19:38 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_advmod_phrases_</th>\n",
       "      <td>0</td>\n",
       "      <td>55 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 13:52:10 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_clauses__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>134 MB</td>\n",
       "      <td>created by soras on Thu Jun  1 17:03:45 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__laye</th>\n",
       "      <td>0</td>\n",
       "      <td>46 MB</td>\n",
       "      <td>created by soras on Mon Jan  2 12:39:29 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_obl_phrases__la</th>\n",
       "      <td>0</td>\n",
       "      <td>76 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 14:02:59 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_pre_timexes__la</th>\n",
       "      <td>0</td>\n",
       "      <td>55 MB</td>\n",
       "      <td>created by soras on Wed Mar 15 17:53:39 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_stanza_syntax__</th>\n",
       "      <td>0</td>\n",
       "      <td>224 MB</td>\n",
       "      <td>created by soras on Thu Jan 26 14:09:38 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">koondkorpus_words_v16_1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>2718 MB</td>\n",
       "      <td>example sentence for every word in koondkorpus_base__v16_1_words__layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       " There are collections listed in the __collections table without tables in the database: ['koondkorpus_syntax_subset']"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x16643496ee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helper_functions import load_configuration, connect_to_database\n",
    "\n",
    "config = load_configuration('config\\example_configuration.ini')\n",
    "storage = connect_to_database(config)\n",
    "\n",
    "display(storage)\n",
    "\n",
    "collection = config['source_database']['collection']\n",
    "collection = storage[collection]\n",
    "\n",
    "collection.selected_layers = ['v171_named_entities','v172_geo_terms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65e010",
   "metadata": {},
   "source": [
    "Read the geographical terms from WordNet that can be a part of a named geographical entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e855a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 63 terms.\n"
     ]
    }
   ],
   "source": [
    "terms = []\n",
    "with open('geo_terms.txt', 'r', encoding='UTF-8') as in_f:\n",
    "    for line in in_f:\n",
    "        if len(line.strip()) > 0:\n",
    "            terms.append( line.strip() )\n",
    "print(f'Loaded {len(terms)} terms.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8c664",
   "metadata": {},
   "source": [
    "Initialize SpanSampler that uses a local sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75db3c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_sampling_db:  geo_terms_sample.db (exists: True)\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from helper_functions import load_local_configuration\n",
    "\n",
    "config = load_local_configuration('config/example_configuration.ini')\n",
    "sampling_db = config['local_database']['sqlite_file']\n",
    "print(f'local_sampling_db:  {sampling_db} (exists: {os.path.exists(sampling_db)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b9ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 63 terms from geo_terms.txt.\n"
     ]
    }
   ],
   "source": [
    "from span_sampler_sqlite3 import SpanSampler\n",
    "\n",
    "sampler = SpanSampler(collection=collection, \n",
    "                      layer=config['source_database']['terms_layer'], \n",
    "                      attribute='lemma', \n",
    "                      termsfile='geo_terms.txt', \n",
    "                      db_file_name=config['local_database']['sqlite_file'], \n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61946477",
   "metadata": {},
   "source": [
    "Before sampling, all terms that are subject sampling need to be searched from the large source database and recorded into a smaller local database, so that sampling can be quick and smooth. This searching and indexing process can take several hours. \n",
    "\n",
    "**Note:** If you already have the local database populated with term locations, then the next command produces a warning and skips the local database creation. If you still want to repeat the local database creation from the scratch, then you should delete the local database file before creating SpanSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867289c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Kraam\\estnltk_1.7_aux\\estnltk-model-data\\named_entity_recognition\\recall_estimation\\data_generation\\amundsen_01\\span_sampler_sqlite3.py:69: UserWarning: (!) 'geo_terms_sample.db' already contains attribute_locations table. Skipping the table creation.\n",
      "  warnings.warn(f'(!) {self._db_file_name!r} already contains attribute_locations table. Skipping the table creation.')\n"
     ]
    }
   ],
   "source": [
    "# search and index terms (can take several hours if done from the scratch)\n",
    "sampler.create_attribute_locations_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b627f",
   "metadata": {},
   "source": [
    "Once indexing is completed, we can start sampling from the local database. \n",
    "We can create the samples by calling the sampler, specifying the count of samples we want and a filter which is a list of attribute values for the attribute specified before (lemma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bda7883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Text(text='Ükstaspuha , mis kanali telekas lahti teed , igal pool võid näha .'),\n",
       "  Span('lahti', [{'lemma': 'laht'}])),\n",
       " (Text(text='Eduard veerib Edda käekirja pärast lahti ja toimetab üle .'),\n",
       "  Span('lahti', [{'lemma': 'laht'}])),\n",
       " (Text(text='Mäletame plaane muuta suurte Siberi jõgede voolusuunda , ehitada tamm Beringi väina jne.'),\n",
       "  Span('jõgede', [{'lemma': 'jõgi'}]))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = sampler(count=1000, attribute_values=tuple(terms))\n",
    "display(samples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f391a",
   "metadata": {},
   "source": [
    "Note that our terms have been divided into **subpopulations** by their frequency/ambiguity:\n",
    "\n",
    "|Subpopulation     | Description | Examples |\n",
    "|:--- |:---|:---|\n",
    "|Levinumad         | Geographic locations with most frequent suffixes | Niiluse jõgi, Aasovi meri, Peipsi järv   |  \n",
    "|Mitmetäheduslikud | Geographic locations with ambigous suffixes      | Panama kanal, Panga pank, Kura kurk      |\n",
    "|Ülejäänud         | Other geographic locations                       | Vaikne ookean, Liivi laht, Tehvandi mägi |  \n",
    "\n",
    "Let's load subpopulation information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055b981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['levinumad', 'mitmetahenduslikud', 'ulejaanud'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_functions import load_term_subpopulations\n",
    "term_subpopulations = load_term_subpopulations()\n",
    "term_subpopulations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f54e468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'järv', 'jõgi', 'meri', 'saar'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_subpopulations['levinumad']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8280dec",
   "metadata": {},
   "source": [
    "Now we can draw samples from each subpopulation separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e70798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Text(text='Algul segas armunute vaadet imekaunile järvele ilmatu suur pruun kuur , tänaseks on see maha lõhutud .'),\n",
       "  Span('järvele', [{'lemma': 'järv'}])),\n",
       " (Text(text='Ja teen kontserte selliste rituaalide ja suunitlusega , et soovime Eesti riigile samasugust saatust , mis valitseb praegu Bali saarel .'),\n",
       "  Span('saarel', [{'lemma': 'saar'}])),\n",
       " (Text(text='Üks tehase omanike esindajaist nimetas “ haiglaseks urgitsemiseks ” küsimust , millise summa eest müüdi hotell Bahama saarte firmale Rahmsad Investors Ltd.'),\n",
       "  Span('saarte', [{'lemma': 'saar'}]))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_levinumad = sampler(count=1000, attribute_values=tuple(term_subpopulations['levinumad']))\n",
    "display(samples_levinumad[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6e6c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Text(text='Ühelt poolt domineerivad börsil pankade endi aktsiad , teisalt aga tegutsevad pangad ise või oma tütarfirmade kaudu börsil maakleritena .'),\n",
       "  Span('pankade', [{'lemma': 'pank'}])),\n",
       " (Text(text='Peamisi samme oli pankade kapitali adekvaatsusnormatiivi tõstmine , lisaks sellele suurendasime riskikaalusid ka kohalike omavalitsuste laenudele .'),\n",
       "  Span('pankade', [{'lemma': 'pank'}])),\n",
       " (Text(text='Kui uued juhid olid panga paremini tööle pannud , müüsime oma osa järgmisele pangale juba tunduvalt suurema summa eest , ” on pankade saneerimist lähedalt näinud Preatoni konkreetne .'),\n",
       "  Span('pangale', [{'lemma': 'pank'}]))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_mitmetahenduslikud = sampler(count=1000, attribute_values=tuple(term_subpopulations['mitmetahenduslikud']))\n",
    "display(samples_mitmetahenduslikud[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5438687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Text(text='Suudan tõtt vaadata ainult nende asjadega , mis on mu ninast paari sentimeetri kaugusel .'),\n",
       "  Span('ninast', [{'lemma': 'ninas'}])),\n",
       " (Text(text='Kui nooremas ja depressiivsemas vanuses oli mul selles kahtlusi , siis praeguseks olen jõudnud tõdemuseni , et see on väga lahe - lihtsalt elada !'),\n",
       "  Span('lahe', [{'lemma': 'laht'}])),\n",
       " (Text(text='Teise allika sõnul tegi Katariina kunagi New Yorgis hea partii , abielludes kellegi sealse miljonäriga .'),\n",
       "  Span('allika', [{'lemma': 'allikas'}]))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ulejaanud = sampler(count=1000, attribute_values=tuple(term_subpopulations['ulejaanud']))\n",
    "display(samples_ulejaanud[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef8a68",
   "metadata": {},
   "source": [
    "## II. Creating unlabelled samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98447f47",
   "metadata": {},
   "source": [
    "Currently, there is no good way to check for duplicates. All pairs of items should be compared in a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f298c",
   "metadata": {},
   "source": [
    "Once a span is sampled, take its text and remove all other spans from it so that only the sampled span would be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f471917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "for text, sample_span in samples_levinumad:\n",
    "    for span in copy(text.v172_geo_terms.spans):\n",
    "        if span != sample_span:\n",
    "            text.v172_geo_terms.remove_span(span)\n",
    "\n",
    "for text, sample_span in samples_mitmetahenduslikud:\n",
    "    for span in copy(text.v172_geo_terms.spans):\n",
    "        if span != sample_span:\n",
    "            text.v172_geo_terms.remove_span(span)\n",
    "\n",
    "for text, sample_span in samples_ulejaanud:\n",
    "    for span in copy(text.v172_geo_terms.spans):\n",
    "        if span != sample_span:\n",
    "            text.v172_geo_terms.remove_span(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3241f",
   "metadata": {},
   "source": [
    "After samples have been finalized, they are put into a pickle file so they could be easily reused at a later time or a different place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f184ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"unlabelled_data/sampled_sentences/1000_levinumad.pickle\",'wb') as f:\n",
    "    pickle.dump(samples_levinumad, f)\n",
    "\n",
    "with open(\"unlabelled_data/sampled_sentences/1000_mitmetahenduslikud.pickle\",'wb') as f:\n",
    "    pickle.dump(samples_mitmetahenduslikud, f)\n",
    "    \n",
    "with open(\"unlabelled_data/sampled_sentences/1000_ulejaanud.pickle\",'wb') as f:\n",
    "    pickle.dump(samples_ulejaanud, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7f49a",
   "metadata": {},
   "source": [
    "### Getting sentences to labelstudio format\n",
    "\n",
    "Labelstudio exporter writes labelstudio JSON file to the file given as argument here. This should be exported to the project you set up in labelstudio. Labelstudio offers different labeling interfaces but also a possibility to define it with code. The code outputted by _exporter.labeling_interface_ can be copied to the labeling interface code part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da97caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "samples = {}\n",
    "for subpopulation in ['levinumad', 'mitmetahenduslikud', 'ulejaanud']:\n",
    "    with open(f\"unlabelled_data/sampled_sentences/1000_{subpopulation}.pickle\", 'rb') as f:\n",
    "        samples[subpopulation] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "41509c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.converters.label_studio.label_studio import LabelStudioExporter\n",
    "\n",
    "for subpopulation in ['levinumad', 'mitmetahenduslikud', 'ulejaanud']:\n",
    "    exporter = LabelStudioExporter(f\"unlabelled_data/sampled_sentences_ls_format/koond_1000_{subpopulation}.json\",\n",
    "                                   'v172_geo_terms',\n",
    "                                   checkbox=True)\n",
    "    print(exporter.labeling_interface)\n",
    "    only_texts = [sample[0] for sample in samples[subpopulation]]\n",
    "    exporter.convert(only_texts, append=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
