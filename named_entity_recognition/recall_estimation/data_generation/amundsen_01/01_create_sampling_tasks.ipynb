{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e316e75",
   "metadata": {},
   "source": [
    "# Workflow for searching new recall samples\n",
    "\n",
    "Finds a random sample of potential positive samples. Converts these to labelstudio format for manual tagging. For this specific task, we create three different subsamples based on the geographic term. This is to improve the accuracy of the recall estimation by grouping samples to groups where the tagger might get different results. The groups here are: most common geographic terms, geographic terms that are homonyms of some more popular word and all the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e8cac",
   "metadata": {},
   "source": [
    "## I. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d494a28",
   "metadata": {},
   "source": [
    "### Loading the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a3d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:58: connecting to host: 'postgres.keeleressursid.ee', port: 5432, dbname: 'estonian-text-corpora', user: 'rasmusm'\n",
      "INFO:storage.py:108: schema: 'estonian_text_corpora', temporary: False, role: 'estonian_text_corpora_read'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "user=rasmusm password=xxx dbname=estonian-text-corpora host=postgres.keeleressursid.ee port=5432 schema=estonian_text_corpora<br/>temporary=False<br/>\n",
       "collection count: 5\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>total_size</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <th>version</th>\n",
       "      <th>relations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">koondkorpus_base_subset_of_5000_v2</th>\n",
       "      <th rowspan=\"16\" valign=\"top\">2.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>12 MB</td>\n",
       "      <td>Collection of 5000 randomly picked Koondkorpus texts (v2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_sentences_flat__la</th>\n",
       "      <td>0</td>\n",
       "      <td>5544 kB</td>\n",
       "      <td>created by soras on Fri Jun 12 11:28:06 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>19 MB</td>\n",
       "      <td>created by soras on Fri Jun 12 09:15:46 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words_morph_analys</th>\n",
       "      <td>0</td>\n",
       "      <td>96 MB</td>\n",
       "      <td>Morphological analysis from v1.6.2/3, probably based on commit 349a7c2 (2018-11-22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>2</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_compound_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>5472 kB</td>\n",
       "      <td>created by soras on Thu Jun  4 12:29:42 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_morph_analysis__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>97 MB</td>\n",
       "      <td>created by soras on Tue Jun  9 14:13:07 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_sentences__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>21 MB</td>\n",
       "      <td>created by soras on Tue Jun  9 06:01:41 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>20 MB</td>\n",
       "      <td>created by soras on Thu Jun  4 07:40:39 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>20 MB</td>\n",
       "      <td>created by soras on Fri Jun  5 05:49:26 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_ensemble_syntax</th>\n",
       "      <td>0</td>\n",
       "      <td>95 MB</td>\n",
       "      <td>created by soras on Wed Aug  4 08:53:37 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_pos_based_synta</th>\n",
       "      <td>0</td>\n",
       "      <td>77 MB</td>\n",
       "      <td>created by soras on Wed Aug 11 17:26:41 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>95 MB</td>\n",
       "      <td>created by soras on Fri Jul  2 16:07:05 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_clauses__layer</th>\n",
       "      <td>5000</td>\n",
       "      <td>22 MB</td>\n",
       "      <td>created by soras on Mon Sep 12 11:26:29 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_named_entities__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>5624 kB</td>\n",
       "      <td>created by soras on Tue May 17 11:01:56 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__layer</th>\n",
       "      <td>5000</td>\n",
       "      <td>1896 kB</td>\n",
       "      <td>created by soras on Mon Jan  2 12:25:16 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">koondkorpus_base_v2</th>\n",
       "      <th rowspan=\"16\" valign=\"top\">2.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>1618 MB</td>\n",
       "      <td>Collection of Koondkorpus texts (v2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_sentences_flat__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>740 MB</td>\n",
       "      <td>created by soras on Mon Jun 15 06:44:30 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2553 MB</td>\n",
       "      <td>created by soras on Fri Jun 12 12:25:44 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_words_morph_analysis__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>13 GB</td>\n",
       "      <td>Morphological analysis from v1.6.2/3, probably based on commit 349a7c2 (2018-11-22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>2</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_compound_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>698 MB</td>\n",
       "      <td>created by soras on Thu Jun  4 12:36:01 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_morph_analysis__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>13 GB</td>\n",
       "      <td>created by soras on Tue Jun  9 14:32:08 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_sentences__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2860 MB</td>\n",
       "      <td>created by soras on Tue Jun  9 06:07:08 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_tokens__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2587 MB</td>\n",
       "      <td>created by soras on Thu Jun  4 07:42:49 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v166_words__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>2622 MB</td>\n",
       "      <td>created by soras on Fri Jun  5 05:53:18 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_ensemble_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>12 GB</td>\n",
       "      <td>created by soras on Thu Aug  5 17:31:45 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_pos_based_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>10 GB</td>\n",
       "      <td>created by soras on Thu Aug 12 18:03:09 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v168_stanza_syntax__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>12 GB</td>\n",
       "      <td>created by soras on Wed Jul 28 10:45:04 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_clauses__layer</th>\n",
       "      <td>703506</td>\n",
       "      <td>2884 MB</td>\n",
       "      <td>created by soras on Mon Sep 12 11:46:59 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v169_named_entities__layer</th>\n",
       "      <td>0</td>\n",
       "      <td>752 MB</td>\n",
       "      <td>created by soras on Tue May 17 14:29:05 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__layer</th>\n",
       "      <td>705356</td>\n",
       "      <td>247 MB</td>\n",
       "      <td>created by soras on Mon Jan  2 12:30:20 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">koondkorpus_sentences</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">3.0</th>\n",
       "      <th></th>\n",
       "      <td>21377855</td>\n",
       "      <td>82 GB</td>\n",
       "      <td>koondkorpus_base_v2 texts split into sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>11</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v171_named_entities__layer</th>\n",
       "      <td>18950492</td>\n",
       "      <td>7452 MB</td>\n",
       "      <td>created by soras on Mon Dec  5 11:27:53 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_advmod_phrases__layer</th>\n",
       "      <td>10650949</td>\n",
       "      <td>7416 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 14:49:31 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__layer</th>\n",
       "      <td>21237460</td>\n",
       "      <td>6187 MB</td>\n",
       "      <td>created by soras on Wed Jan  4 11:12:06 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_obl_phrases__layer</th>\n",
       "      <td>12228238</td>\n",
       "      <td>10027 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 14:44:17 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_stanza_syntax__layer</th>\n",
       "      <td>21399587</td>\n",
       "      <td>29 GB</td>\n",
       "      <td>created by soras on Thu Jan 26 15:12:12 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">koondkorpus_sentences_test_5000_sg_thread</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">3.0</th>\n",
       "      <th></th>\n",
       "      <td>159829</td>\n",
       "      <td>652 MB</td>\n",
       "      <td>5000 texts split into sentences (based on v2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>11</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v171_named_entities_</th>\n",
       "      <td>146503</td>\n",
       "      <td>62 MB</td>\n",
       "      <td>created by soras on Fri Dec  2 16:19:38 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_advmod_phrases_</th>\n",
       "      <td>78365</td>\n",
       "      <td>55 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 13:52:10 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_geo_terms__laye</th>\n",
       "      <td>159745</td>\n",
       "      <td>46 MB</td>\n",
       "      <td>created by soras on Mon Jan  2 12:39:29 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_obl_phrases__la</th>\n",
       "      <td>91550</td>\n",
       "      <td>76 MB</td>\n",
       "      <td>created by soras on Tue Jan 31 14:02:59 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v172_stanza_syntax__</th>\n",
       "      <td>159745</td>\n",
       "      <td>224 MB</td>\n",
       "      <td>created by soras on Thu Jan 26 14:09:38 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">koondkorpus_words_v16_1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>2718 MB</td>\n",
       "      <td>example sentence for every word in koondkorpus_base__v16_1_words__layer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       " There are collections listed in the __collections table without tables in the database: ['koondkorpus_syntax_subset']"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x2685c7a30f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from estnltk.storage.postgres import PostgresStorage\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config_file = 'config\\example_configuration.ini'\n",
    "\n",
    "file_name = os.path.abspath(os.path.expanduser(os.path.expandvars(str(config_file))))\n",
    "config.read(file_name)\n",
    "\n",
    "dbname = config['source_database']['database']\n",
    "user = config['source_database']['username']\n",
    "password = config['source_database']['password']\n",
    "host = config['source_database']['host']\n",
    "port = config['source_database']['port']\n",
    "role = config['source_database']['role']\n",
    "schema = config['source_database']['schema']\n",
    "collection = config['source_database']['collection']\n",
    "\n",
    "\n",
    "storage = PostgresStorage(host=host,\n",
    "                          port=int(port),\n",
    "                          dbname=dbname,\n",
    "                          user=user,\n",
    "                          password=password,\n",
    "                          schema=schema,\n",
    "                          role=role,\n",
    "                          temporary=False)\n",
    "\n",
    "display(storage)\n",
    "\n",
    "collection = storage[collection]\n",
    "\n",
    "collection.selected_layers = ['v171_named_entities','v172_geo_terms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65e010",
   "metadata": {},
   "source": [
    "Read the geographical terms from WordNet that can be a part of a named geographical entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e855a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = []\n",
    "with open('geo_terms.txt','r',encoding='UTF-8') as f:\n",
    "    term = f.readline()\n",
    "    while term is not '':\n",
    "        terms.append(term.strip())\n",
    "        term = f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcea11d",
   "metadata": {},
   "source": [
    "### Span Sampler\n",
    "\n",
    "Python class for sampling spans. Create a local database and a table in it with a row for each span. This means that each term can be sampled separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "73e32736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, choices\n",
    "from estnltk.storage.postgres import LayerQuery, IndexQuery\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SpanSampler:\n",
    "    \n",
    "    def __init__(self, storage, collection, layer, attribute):\n",
    "        self.storage = storage\n",
    "        self.conn = storage.conn\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.collection = collection\n",
    "        self.layer = layer\n",
    "        self.attribute = attribute\n",
    "    \n",
    "    def __call__(self, count, attribute, return_index=False, with_replacement=True): \n",
    "        # Returns iterator of type Text, Span or int, Text, span\n",
    "        # count determines the number of samples\n",
    "        # with replacement means that same span can be sampled several times\n",
    "        self.conn.commit()\n",
    "        self.create_sampling_matrix(attribute)\n",
    "        indices = self.find_sampled_indices(count,with_replacement)\n",
    "        result_list = []\n",
    "        only_txt_index = [idx[1] for idx in indices]\n",
    "        texts = list(collection.select( query=IndexQuery(only_txt_index),layers=[self.layer],return_index=True ))\n",
    "        for text in texts:\n",
    "            idx = [index for index in indices if text[0] == index[1]][0]\n",
    "            if return_index:\n",
    "                result_list.append((idx[0],text[1],text[1][self.layer][idx[2]]))\n",
    "            else:\n",
    "                result_list.append((text[1],text[1][self.layer][idx[2]]))\n",
    "        self.clear_sampling_matrix()\n",
    "        return result_list\n",
    "    \n",
    "    def attribute_locations_creation(self):\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(\"\"\"SELECT EXISTS (\n",
    "           SELECT FROM information_schema.tables \n",
    "           WHERE  table_schema = 'public'\n",
    "           AND    table_name   = 'attribute_locations'\n",
    "           );\"\"\")\n",
    "        res = self.cur.fetchall()\n",
    "        if not res[0][0]:\n",
    "            self.cur.execute(\"CREATE TABLE attribute_locations (layer_id integer, attribute_value varchar, indices integer[], count integer);\")\n",
    "            self.conn.commit()\n",
    "            for term in terms:\n",
    "                q = LayerQuery('v172_geo_terms', lemma=term)\n",
    "                for key, txt in tqdm(collection.select(query=q,layers=['v172_geo_terms'])):\n",
    "                    indices = [i for i, nertag in enumerate(txt['v172_geo_terms']['lemma']) if nertag[0] ==term]\n",
    "                    self.cur.execute(\"INSERT INTO attribute_locations (layer_id, attribute_value,indices,count) VALUES (%s, %s, %s, %s)\",(key, term, indices,len(indices)))\n",
    "\n",
    "        self.conn.commit()\n",
    "\n",
    "        \n",
    "    def create_sampling_matrix(self,attribute_val):\n",
    "        self.cur.execute(\"CREATE TABLE sampling_matrix (id serial, layer integer, layer_index integer);\")\n",
    "        self.cur.execute(\"INSERT INTO sampling_matrix (layer,layer_index) (SELECT layer_id as layer, unnest(indices) as layer_index FROM attribute_locations WHERE attribute_value IN \" + str(attribute_val) + \");\")\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def find_sampled_indices(self,count,with_replacement):\n",
    "        self.cur.execute(\"SELECT COUNT(*) FROM sampling_matrix;\")\n",
    "        span_count = self.cur.fetchall()[0][0]\n",
    "        self.conn.commit()\n",
    "        if with_replacement:\n",
    "            sampled = choices(range(span_count),k=count)\n",
    "        else:\n",
    "            sampled = sample(range(span_count),count)\n",
    "        self.cur.execute(\"SELECT * FROM sampling_matrix WHERE id IN \" + str(tuple(sampled)) + ';')\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def clear_sampling_matrix(self):\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(\"DROP TABLE sampling_matrix;\")\n",
    "        self.conn.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d9520",
   "metadata": {},
   "source": [
    "Initialize a local Postgres collection. This is necessary for the temporary table of spans from which the sampling is done which should not be a public table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9dee26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PostgresStorage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ad2b2a7ef9ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Second storage to keep the temporary lists used for sampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m localstorage = PostgresStorage(host='localhost',\n\u001b[0m\u001b[0;32m      3\u001b[0m                           \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5432\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mdbname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ner_test'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'postgres'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PostgresStorage' is not defined"
     ]
    }
   ],
   "source": [
    "# Second storage to keep the temporary lists used for sampling\n",
    "\n",
    "# load configuration\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config_file = 'config\\example_configuration.ini'\n",
    "\n",
    "file_name = os.path.abspath(os.path.expanduser(os.path.expandvars(str(config_file))))\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    raise ValueError(\"File {file} does not exist\".format(file=str(config_file)))\n",
    "\n",
    "if len(config.read(file_name)) != 1:\n",
    "    raise ValueError(\"File {file} is not accessible or is not in valid INI format\".format(file=config_file))\n",
    "\n",
    "for option in [\"host\", \"port\", \"database\", \"username\", \"password\", \"schema\", \"collection\"]:\n",
    "    if not config.has_option('target_database', option):\n",
    "        prelude = \"Error in file {}\\n\".format(file_name) if len(file_name) > 0 else \"\"\n",
    "        raise ValueError(\n",
    "            \"{prelude}Missing option {option} in the section [{section}]\".format(\n",
    "                prelude=prelude, option=option, section='target_database'\n",
    "            )\n",
    "        )\n",
    "\n",
    "config.read(file_name)\n",
    "\n",
    "# connect to database\n",
    "\n",
    "from estnltk.storage.postgres import PostgresStorage\n",
    "\n",
    "dbname = config['target_database']['database']\n",
    "user = config['target_database']['username']\n",
    "password = config['target_database']['password']\n",
    "host = config['target_database']['host']\n",
    "port = config['target_database']['port']\n",
    "schema = config['target_database']['schema']\n",
    "collection = config['target_database']['collection']\n",
    "\n",
    "localstorage = PostgresStorage(host=host,\n",
    "                          port=int(port),\n",
    "                          dbname=dbname,\n",
    "                          user=user,\n",
    "                          password=password,\n",
    "                          schema=schema,\n",
    "                          role=None,\n",
    "                          temporary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b627f",
   "metadata": {},
   "source": [
    "The sampler here is initialized to work with the localstorage and the collection connection we opened up. On initializing, if the table is not created yet, it creates a local table of all spans from the layer _v172_geo_terms_ and also saves the attribute _lemma_ for each span.\n",
    "\n",
    "Then we create the samples by calling the sampler, specifying the count of samples we want and a filter which is a list of attribute values for the attribute specified before (lemma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "24622aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SpanSampler(storage=localstorage,collection=collection, layer='v172_geo_terms',attribute='lemma')\n",
    "\n",
    "#localstorage.conn.commit()\n",
    "\n",
    "#sampler.clear_sampling_matrix()\n",
    "\n",
    "samples = sampler(count=1000,attribute=tuple(filtered_terms))\n",
    "\n",
    "display(samples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef8a68",
   "metadata": {},
   "source": [
    "## II. Creating unlabelled samples \n",
    "\n",
    "After creating the samples, they are put to a pickle file so they could be easily reused at a later time or a different place.\n",
    "\n",
    "Currently, there is no good way to check for duplicates. All pairs of items should be compared in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "907e5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"1000_ulejaanud.pickle\",'wb') as f:\n",
    "    pickle.dump(samples,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f298c",
   "metadata": {},
   "source": [
    "Once a span is sampled, take its text and remove all other spans from it so that only the sampled span would be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f471917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "for text, sample_span in samples:\n",
    "    for span in copy(text.v172_geo_terms.spans):\n",
    "        if span != sample_span:\n",
    "            text.v172_geo_terms.remove_span(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7f49a",
   "metadata": {},
   "source": [
    "### Getting sentences to labelstudio format\n",
    "\n",
    "Labelstudio exporter writes labelstudio JSON file to the file given as argument here. This should be exported to the project you set up in labelstudio. Labelstudio offers different labeling interfaces but also a possibility to define it with code. The code outputted by _exporter.labeling_interface_ can be copied to the labeling interface code part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "41509c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.converters.label_studio.label_studio import LabelStudioExporter\n",
    "\n",
    "exporter = LabelStudioExporter(\"koond_1000_ulejaanud.json\",'v172_geo_terms',checkbox=True)\n",
    "\n",
    "print(exporter.labeling_interface)\n",
    "\n",
    "only_texts = [sample[0] for sample in samples]\n",
    "\n",
    "exporter.convert(only_texts,append=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
