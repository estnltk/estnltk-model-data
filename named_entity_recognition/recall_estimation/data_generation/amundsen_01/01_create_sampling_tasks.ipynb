{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e316e75",
   "metadata": {},
   "source": [
    "# Workflow for searching new recall samples\n",
    "\n",
    "* Explain what this workflow does\n",
    "* Explain what what one should do with output files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e8cac",
   "metadata": {},
   "source": [
    "## I. Setup\n",
    "\n",
    "* Explain why we need subsamples and which files define them.\n",
    "* Clean the cells so that there only these that are absolutely necesary\n",
    "* You can add asserts to diagnose potential errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b61490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae49e6f1",
   "metadata": {},
   "source": [
    "**TODO:** remove these lines when the file is complete. It is not a goot stile in production code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f66c07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d494a28",
   "metadata": {},
   "source": [
    "### Loading the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4849bbf",
   "metadata": {},
   "source": [
    "**TODO:** The following cell is evil. You will commit the password sooner or later\n",
    "\n",
    "* Introduce configparser based solution\n",
    "\n",
    "https://github.com/estnltk/syntax_experiments/blob/syntax_consistency/collection_splitting/1_collection_splitting.py\n",
    "Lines 20-43\n",
    "\n",
    "Push this into EstNLTK so that we do not have to reinvent this every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a3d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:58: connecting to host: 'postgres.keeleressursid.ee', port: 5432, dbname: 'estonian-text-corpora', user: 'rasmusm'\n",
      "INFO:storage.py:108: schema: 'estonian_text_corpora', temporary: False, role: 'estonian_text_corpora_read'\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.storage.postgres import PostgresStorage, create_schema\n",
    "\n",
    "\n",
    "storage = PostgresStorage(host='postgres.keeleressursid.ee',\n",
    "                          port=5432,\n",
    "                          dbname='estonian-text-corpora',\n",
    "                          user='rasmusm',\n",
    "                          password='',\n",
    "                          schema='estonian_text_corpora',\n",
    "                          role='estonian_text_corpora_read',\n",
    "                          temporary=False)\n",
    "\n",
    "display(storage)\n",
    "\n",
    "collection = storage['koondkorpus_sentences']\n",
    "\n",
    "collection.selected_layers = ['v171_named_entities','v172_geo_terms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65e010",
   "metadata": {},
   "source": [
    "**TODO:** Explain why do you do the following thing and what one should to with the resulting file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e855a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = []\n",
    "with open('geo_terms.txt','r',encoding='UTF-8') as f:\n",
    "    term = f.readline()\n",
    "    while term is not '':\n",
    "        terms.append(term.strip())\n",
    "        term = f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcea11d",
   "metadata": {},
   "source": [
    "### Local copy of Span Sampler\n",
    "\n",
    "**TODO:** This header is uninformative. Say Why do you do this?\n",
    "What are the steps to complete this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def attribute_locations_creation(self):\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(\"\"\"SELECT EXISTS (\n",
    "           SELECT FROM information_schema.tables \n",
    "           WHERE  table_schema = 'public'\n",
    "           AND    table_name   = 'attribute_locations'\n",
    "           );\"\"\")\n",
    "        res = self.cur.fetchall()\n",
    "        if not res[0][0]:\n",
    "            self.cur.execute(\"CREATE TABLE attribute_locations (layer_id integer, attribute_value varchar, indices integer[], count integer);\")\n",
    "            self.conn.commit()\n",
    "            for term in terms:\n",
    "                q = LayerQuery('v172_geo_terms', lemma=term)\n",
    "                for key, txt in tqdm(collection.select(query=q,layers=['v172_geo_terms'])):\n",
    "                    indices = [i for i, nertag in enumerate(txt['v172_geo_terms']['lemma']) if nertag[0] ==term]\n",
    "                    self.cur.execute(\"INSERT INTO attribute_locations (layer_id, attribute_value,indices,count) VALUES (%s, %s, %s, %s)\",(key, term, indices,len(indices)))\n",
    "\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ee4d9",
   "metadata": {},
   "source": [
    "**TODO:** Abstract this away into EstNLTK library. Qoes probably under storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "73e32736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, choices\n",
    "from estnltk.storage.postgres import LayerQuery, IndexQuery\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SpanSampler:\n",
    "    \n",
    "    def __init__(self, storage, collection, layer, attribute):\n",
    "        self.storage = storage\n",
    "        self.conn = storage.conn\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.collection = collection\n",
    "        self.layer = layer\n",
    "        self.attribute = attribute\n",
    "    \n",
    "    def __call__(self, count, attribute, return_index=False, with_replacement=True): \n",
    "        # Returns iterator of type Text, Span or int, Text, span\n",
    "        # count determines the number of samples\n",
    "        # with replacement means that same span can be sampled several times\n",
    "        self.conn.commit()\n",
    "        self.create_sampling_matrix(attribute)\n",
    "        indices = self.find_sampled_indices(count,with_replacement)\n",
    "        result_list = []\n",
    "        only_txt_index = [idx[1] for idx in indices]\n",
    "        texts = list(collection.select( query=IndexQuery(only_txt_index),layers=[self.layer],return_index=True ))\n",
    "        for text in texts:\n",
    "            idx = [index for index in indices if text[0] == index[1]][0]\n",
    "            if return_index:\n",
    "                result_list.append((idx[0],text[1],text[1][self.layer][idx[2]]))\n",
    "            else:\n",
    "                result_list.append((text[1],text[1][self.layer][idx[2]]))\n",
    "        self.clear_sampling_matrix()\n",
    "        return result_list\n",
    "    \n",
    "\n",
    "        \n",
    "    def create_sampling_matrix(self,attribute_val):\n",
    "        self.cur.execute(\"CREATE TABLE sampling_matrix (id serial, layer integer, layer_index integer);\")\n",
    "        self.cur.execute(\"INSERT INTO sampling_matrix (layer,layer_index) (SELECT layer_id as layer, unnest(indices) as layer_index FROM attribute_locations WHERE attribute_value IN \" + str(attribute_val) + \");\")\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def find_sampled_indices(self,count,with_replacement):\n",
    "        self.cur.execute(\"SELECT COUNT(*) FROM sampling_matrix;\")\n",
    "        span_count = self.cur.fetchall()[0][0]\n",
    "        self.conn.commit()\n",
    "        if with_replacement:\n",
    "            sampled = choices(range(span_count),k=count)\n",
    "        else:\n",
    "            sampled = sample(range(span_count),count)\n",
    "        self.cur.execute(\"SELECT * FROM sampling_matrix WHERE id IN \" + str(tuple(sampled)) + ';')\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def clear_sampling_matrix(self):\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(\"DROP TABLE sampling_matrix;\")\n",
    "        self.conn.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d9520",
   "metadata": {},
   "source": [
    "**TODO:** Why do we need a separate Postgre installation. Can't we use a different schema. Again pack the arguments into config files.\n",
    "If you do that then you have to explain only what must be possible for this schema configuration. It would make a create sense to have a single configuration file with different section names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9dee26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PostgresStorage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ad2b2a7ef9ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Second storage to keep the temporary lists used for sampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m localstorage = PostgresStorage(host='localhost',\n\u001b[0m\u001b[0;32m      3\u001b[0m                           \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5432\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mdbname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ner_test'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'postgres'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PostgresStorage' is not defined"
     ]
    }
   ],
   "source": [
    "# Second storage to keep the temporary lists used for sampling\n",
    "localstorage = PostgresStorage(host='localhost',\n",
    "                          port=5432,\n",
    "                          dbname='ner_test',\n",
    "                          user='postgres',\n",
    "                          password='dbpass',\n",
    "                          pgpass_file='~/.pgpass',\n",
    "                          schema='my_schema',\n",
    "                          role=None,\n",
    "                          temporary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ad887",
   "metadata": {},
   "source": [
    "**TODO:** Where do you use the this cursor? If not delete it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c56cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycur = localstorage.conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b627f",
   "metadata": {},
   "source": [
    "**TODO:** Explain what do you do with the samper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "24622aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SpanSampler(storage=localstorage,collection=collection, layer='v172_geo_terms',attribute='lemma')\n",
    "\n",
    "#localstorage.conn.commit()\n",
    "\n",
    "#sampler.clear_sampling_matrix()\n",
    "\n",
    "samples = sampler(count=1000,attribute=tuple(filtered_terms))\n",
    "\n",
    "display(samples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef8a68",
   "metadata": {},
   "source": [
    "## II. Creating unlabelled samples \n",
    "\n",
    "* Explain what do you do with samples after they are stored.\n",
    "* Explain how to check that new samples are not already sampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6fec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "907e5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"1000_ulejaanud.pickle\",'wb') as f:\n",
    "    pickle.dump(samples,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f471917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "for text, sample_span in samples:\n",
    "    for span in copy(text.v172_geo_terms.spans):\n",
    "        if span != sample_span:\n",
    "            text.v172_geo_terms.remove_span(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7f49a",
   "metadata": {},
   "source": [
    "### Getting sentences to labelstudio format\n",
    "\n",
    "**TODO:** What do with the result and combine cells into a single cell block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "41509c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.converters.label_studio.label_studio import LabelStudioExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f25abdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exporter = LabelStudioExporter(\"koond_1000_ulejaanud.json\",'v172_geo_terms',checkbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "12b213d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        <View>\n",
      "            <Labels name=\"label\" toName=\"text\">\n",
      "\t<Label value=\"v172_geo_terms\" background=\"#F888F5\"/> \n",
      "\n",
      "            </Labels>\n",
      "        <Text name=\"text\" value=\"$text\"/>\n",
      "            <Header value=\"Are the annotations correct?\"/>\n",
      "                <Choices name=\"review\" toName=\"text\">\n",
      "                    <Choice value=\"yes\"/>\n",
      "                    <Choice value=\"no\"/>\n",
      "                </Choices>\n",
      "            </View>\n"
     ]
    }
   ],
   "source": [
    "print(exporter.labeling_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0e6d9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_texts = [sample[0] for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c6331589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exporter.convert(only_texts,append=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
