{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041a97c7",
   "metadata": {},
   "source": [
    "## Estimating the optimal sizes for subsamples\n",
    "\n",
    "* As we estimate the recall by linearly combining recalls on different subsamples, subsamples have different impact on the variability of the recall estimate. \n",
    "* In the following, we choose sample sizes that minimise the length of the confidence intervals for the recall.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af19bf",
   "metadata": {},
   "source": [
    "## I. Theoretical derivation\n",
    "\n",
    "Let $\\lambda_1,\\ldots,\\lambda_k$ be the probabilities that a uniformly sampled recall challenge falls into corresponding sub-population.\n",
    "Let $p_1,\\ldots, p_k$ be the probability that the recall challenge is captures by the algorithm in the corresponding sub-population.\n",
    "Then what are the best samples sizes  $N_1,\\ldots, N_k$ that minimise the variance of the recall estimate\n",
    "\\begin{align*}\n",
    "\\widehat{p}=\\sum_{i=1}^k \\lambda_i\\cdot \\widehat{p_i}\n",
    "\\end{align*}\n",
    "where $\\widehat{p_i}$ are traditional point estimates for sub-recalls $p_1,\\ldots,p_k$ under the constraint that $N_1+\\cdots+N_k=N$?   \n",
    "\n",
    "This problem has a unique solution only if all probabilities $p_1,\\ldots, p_k$ are known. If this is the case then there is no need to compute $\\hat{p}$. In the following we derive the sample sizes under simplifying assumption that $p_i\\approx p_j$. Note that the case $p_i=0.5$ will lead to the maximal variance. Hence this approach can be viewed as a way to choose sample sizes in order to minimise the variance in the worst case scenario.  \n",
    "\n",
    "As \n",
    "\n",
    "\\begin{align*}\n",
    "\\widehat{p_i}=\\frac{X_1+\\cdots+X_{N_i}}{N_i} \\qquad\\text{for}\\quad X_i\\sim \\mathrm{Bernoulli(p_i)}\n",
    "\\end{align*}\n",
    "\n",
    "the corresponding sub-variance is\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{Var}(\\widehat{p_i})=\\frac{p_i(1-p_i)}{N_i}\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "and the total variance is\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{Var}(\\widehat{p})=\\sum_{i=1}^k \\lambda_i^2\\cdot \\mathbf{Var}(\\widehat{p_i})\n",
    "=\\sum_{i=1}^k \\frac{\\lambda_i^2}{N_i}\\cdot p_i(1-p_i)\n",
    "\\end{align*}\n",
    "\n",
    "The assumption $p_i=\\mathrm{const}$ allows us to recast the variance minimisation to the following optimisation task\n",
    "\n",
    "\\begin{align*}\n",
    "&\\sum_{i=1}^k \\frac{\\lambda_i^2}{N_i}\\to \\min\\\\\n",
    "&N_1+\\cdots+N_k=N\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The corresponding Lagrange function is \n",
    "\n",
    "\\begin{align*}\n",
    "f_* = \\sum_{i=1}^k \\frac{\\lambda_i^2}{N_i}+\\mu\\cdot \\sum_{i=1}^k N_i\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "By equating the partial derivatives to zero \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial f_*}{\\partial N_i} = -\\frac{\\lambda_i^2}{N_i^2} + \\mu=0.\n",
    "\\end{align*}\n",
    "\n",
    "we get that the optimal solution is\n",
    "\n",
    "\\begin{align*}\n",
    "N_i=\\frac{\\lambda_i}{\\sqrt{\\mu}}\\enspace.\n",
    "\\end{align*}\n",
    "\n",
    "That is, sub-sample sizes must be proportional to the coefficients $\\lambda_i$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbc87a",
   "metadata": {},
   "source": [
    "## II. Tests for the existing implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd48ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sampling import balance_sample_sizes\n",
    "\n",
    "assert all(balance_sample_sizes(np.array([0.5, 0.5]), 10) == [5, 5])\n",
    "assert all(balance_sample_sizes(np.array([0.25, 0.75]), 10) == [2, 8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
