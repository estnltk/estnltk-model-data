{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201813fb",
   "metadata": {},
   "source": [
    "# Preparing data for labelling (phase 2)\n",
    "\n",
    "## I. Manual labelling\n",
    "\n",
    "The goal of manual labelling was to determine whether sampled phrases represent a named entity (NE). \n",
    "More specifically, annotators where given choices for evaluating the match with NE: 'partial match', 'full match' ja 'no'.\n",
    "\n",
    "Also, [Estonian NE annotation guidelines by Laura Katrin Leman and Kairit Sirts](https://docs.google.com/document/d/1gZcNHmSEK3ua6EwsGJJgRUbfOTzSSa6LuQaDvgNThM4/edit#heading=h.ottwb26al57x) were followed.\n",
    "\n",
    "The first phase of manual labelling involved checking of 17 part-of-speech subsets, each containing 100 sentences at maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a85689",
   "metadata": {},
   "source": [
    "## II. New data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b980c",
   "metadata": {},
   "source": [
    "Prepare data for the next annotation phase:\n",
    "* take 17 unlabelled part of speech subsets (1000 samples in each) as a basis;\n",
    "* exclude part of speech subsets that did not contain any partial nor full NE phrase matches in the first phase (O, X, U, P, V, K, J);\n",
    "* exclude sentences that have already been annotated in the first phase;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8f5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73844e83",
   "metadata": {},
   "source": [
    "First, gather sentences and spans that have already been annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "074d78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"labelled/extended_100\"\n",
    "assert os.path.exists(input_dir), \\\n",
    "    f'(!) Missing input dir {input_dir!r}. Complete the first annotation phase and download annotated data.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5008f055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'int' object is not subscriptable\n",
      "{'id': 1001, 'annotations': [{'id': 8, 'completed_by': 1, 'result': [{'value': {'start': 116, 'end': 133, 'text': 'tekitatud kaldale', 'labels': ['v172_geo_terms']}, 'id': 'Kd6TO66VlK', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'choices': ['no']}, 'id': 'J7PutgBJ_X', 'from_name': 'review', 'to_name': 'text', 'type': 'choices', 'origin': 'manual'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2023-06-14T11:03:41.014143Z', 'updated_at': '2023-06-14T11:03:41.014143Z', 'draft_created_at': None, 'lead_time': 49.145, 'prediction': {'id': 1001, 'model_version': 'undefined', 'created_ago': '21\\xa0hours, 28\\xa0minutes', 'result': [{'value': {'start': 116, 'end': 133, 'text': 'tekitatud kaldale', 'idx': 962, 'labels': ['v172_geo_terms']}, 'to_name': 'text', 'from_name': 'label', 'type': 'labels'}], 'score': None, 'cluster': None, 'neighbors': None, 'mislabeling': 0.0, 'created_at': '2023-06-13T13:35:31.154338Z', 'updated_at': '2023-06-13T13:35:31.154338Z', 'task': 1001}, 'result_count': 0, 'unique_id': '7296f92e-634c-4509-a2f9-0ea7c8b3e499', 'last_action': None, 'task': 1001, 'project': 2, 'updated_by': 1, 'parent_prediction': 1001, 'parent_annotation': None, 'last_created_by': None}], 'file_upload': '6d5e52fa-pos_A_1000_ext_100.json', 'drafts': [], 'predictions': [1001], 'data': {'text': '( 1 ) Kalda , ranna või muu maastiku kaitse või kasutamise nõuete rikkumise eest ettevaatamatusest , kui sellega on tekitatud kaldale , rannale või muule maastikule suur kahju , - karistatakse rahalise karistuse või kuni üheaastase vangistusega .'}, 'meta': {}, 'created_at': '2023-06-13T13:35:31.117939Z', 'updated_at': '2023-06-14T11:03:41.072242Z', 'inner_id': 1, 'total_annotations': 1, 'cancelled_annotations': 0, 'total_predictions': 1, 'comment_count': 0, 'unresolved_comment_count': 0, 'last_comment_updated_at': None, 'project': 2, 'updated_by': 1, 'comment_authors': []}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>phrase</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, phrase, text, start, end]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_json_file(filename):    \n",
    "    f = open(filename, encoding=\"utf-8\")\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "already_annotated = []\n",
    "for file in os.listdir(input_dir):\n",
    "    pos = read_json_file(os.path.join(input_dir, file))\n",
    "    try:\n",
    "        for elem in pos:\n",
    "            start  = elem[\"predictions\"][0][\"result\"][0][\"value\"][\"start\"]\n",
    "            end    = elem[\"predictions\"][0][\"result\"][0][\"value\"][\"end\"]\n",
    "            phrase = elem[\"predictions\"][0][\"result\"][0][\"value\"][\"text\"]\n",
    "            text   = elem[\"data\"][\"text\"]\n",
    "            already_annotated.append((file, phrase, text, start, end))\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(elem)\n",
    "        break\n",
    "    #break\n",
    "\n",
    "already_annotated_df = pd.DataFrame(already_annotated, columns=[\"file\", \"phrase\", \"text\", \"start\", \"end\"])\n",
    "already_annotated_df = already_annotated_df.drop_duplicates()\n",
    "already_annotated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f99ca6",
   "metadata": {},
   "source": [
    "**TODO:** Unexpectedly, the previous code does not work because the input data is malformed: it has integers (instead of nested dictionaries) inside the \"predictions\" slot. Remains to be investigated why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95f8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hopeless = [\"pos_O\", \"pos_X\", \"pos_U\", \"pos_P\", \"pos_V\", \"pos_K\", \"pos_J\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cd48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'unlabelled/pos_terms_1000_extended'\n",
    "assert os.path.exists(input_dir), \\\n",
    "    f'(!) Missing input dir {input_dir!r}. Please run \"02_prepare_for_labelling.ipynb\" before running this.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74516157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00, 12.30it/s]\n"
     ]
    }
   ],
   "source": [
    "additional_data = []\n",
    "for file in tqdm(os.listdir(input_dir)):\n",
    "    stop= False\n",
    "    if not any(hl in file for hl in hopeless):\n",
    "        pos = read_json_file(os.path.join(input_dir, file))\n",
    "        orig_file = file[:5]\n",
    "        for elem in pos:\n",
    "            new = True\n",
    "            try:\n",
    "                if len(elem['predictions'][0]['result']) != 0:\n",
    "                    text = elem[\"data\"][\"text\"]\n",
    "                    start = elem['predictions'][0]['result'][0]['value']['start']\n",
    "                    end = elem['predictions'][0]['result'][0]['value']['end']\n",
    "                    phrase = elem['predictions'][0]['result'][0]['value']['text']\n",
    "                    # Check wheter this sentence was previously annotated:\n",
    "                    temp = already_annotated_df[already_annotated_df[\"file\"].str.match(orig_file)]\n",
    "                    for row in temp.iterrows():\n",
    "                        if row[1][1]==phrase and row[1][2]==text and row[1][3]==start and row[1][4]==end:\n",
    "                            # Affirmative: this is not new\n",
    "                            new = False\n",
    "                            break\n",
    "                    if new:        \n",
    "                        additional_data.append((orig_file, phrase, text, start, end))\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                print(orig_file, elem)\n",
    "                stop=True\n",
    "                break\n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9976956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>phrase</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos_A</td>\n",
       "      <td>sooja merd</td>\n",
       "      <td>“ Me armastame sooja merd ning ilusaid ja vana...</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_A</td>\n",
       "      <td>pruunide säärte</td>\n",
       "      <td>Kepka viltu peas , sööstab Ülle pruunide säärt...</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_A</td>\n",
       "      <td>usaldusväärne allikas</td>\n",
       "      <td>“ See lugu kõlab nende esituses paremini kui i...</td>\n",
       "      <td>80</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos_A</td>\n",
       "      <td>kaheksatuhandelist mäge</td>\n",
       "      <td>Teisegi tipptulemuse tegi ta läinud aastal , v...</td>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos_A</td>\n",
       "      <td>kohalikke panku</td>\n",
       "      <td>Valitsus mõjutas kohalikke panku ja kindlustus...</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9053</th>\n",
       "      <td>pos_Z</td>\n",
       "      <td>PIPI-vs-banaanikalajutt: oja</td>\n",
       "      <td>PIPI-vs-banaanikalajutt: oja käskis lugeda ...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>pos_Z</td>\n",
       "      <td>Polla: kanalite</td>\n",
       "      <td>Polla: kanalite statistika</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055</th>\n",
       "      <td>pos_Z</td>\n",
       "      <td>kiisumiisu: raba</td>\n",
       "      <td>kiisumiisu: raba on sinilill</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9056</th>\n",
       "      <td>pos_Z</td>\n",
       "      <td>Polla: kanalite</td>\n",
       "      <td>Polla: kanalite statistika</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9057</th>\n",
       "      <td>pos_Z</td>\n",
       "      <td>raba</td>\n",
       "      <td>raba: räägid sa põnevalt siis , kuulame huviga...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9058 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file                        phrase  \\\n",
       "0     pos_A                    sooja merd   \n",
       "1     pos_A               pruunide säärte   \n",
       "2     pos_A         usaldusväärne allikas   \n",
       "3     pos_A       kaheksatuhandelist mäge   \n",
       "4     pos_A               kohalikke panku   \n",
       "...     ...                           ...   \n",
       "9053  pos_Z  PIPI-vs-banaanikalajutt: oja   \n",
       "9054  pos_Z               Polla: kanalite   \n",
       "9055  pos_Z              kiisumiisu: raba   \n",
       "9056  pos_Z               Polla: kanalite   \n",
       "9057  pos_Z                          raba   \n",
       "\n",
       "                                                   text  start  end  \n",
       "0     “ Me armastame sooja merd ning ilusaid ja vana...     15   25  \n",
       "1     Kepka viltu peas , sööstab Ülle pruunide säärt...     32   47  \n",
       "2     “ See lugu kõlab nende esituses paremini kui i...     80  101  \n",
       "3     Teisegi tipptulemuse tegi ta läinud aastal , v...     77  100  \n",
       "4     Valitsus mõjutas kohalikke panku ja kindlustus...     17   32  \n",
       "...                                                 ...    ...  ...  \n",
       "9053     PIPI-vs-banaanikalajutt: oja käskis lugeda ...      0   28  \n",
       "9054                         Polla: kanalite statistika      0   15  \n",
       "9055                       kiisumiisu: raba on sinilill      0   16  \n",
       "9056                         Polla: kanalite statistika      0   15  \n",
       "9057  raba: räägid sa põnevalt siis , kuulame huviga...      0    4  \n",
       "\n",
       "[9058 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_df = pd.DataFrame(additional_data, columns=[\"file\", \"phrase\", \"text\", \"start\", \"end\"])\n",
    "ext_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b25fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_C': 994,\n",
       " 'pos_A': 991,\n",
       " 'pos_G': 991,\n",
       " 'pos_S': 981,\n",
       " 'pos_N': 979,\n",
       " 'pos_H': 976,\n",
       " 'pos_D': 973,\n",
       " 'pos_Y': 925,\n",
       " 'pos_Z': 902,\n",
       " 'pos_I': 346}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_counts = dict(ext_df[\"file\"].value_counts())\n",
    "file_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d008fb",
   "metadata": {},
   "source": [
    "Export as labelsstudio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b032182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pd_collection_to_ls import collection_to_labelstudio\n",
    "\n",
    "output_dir = 'unlabelled/pos_terms_1000_extended_phase_2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for key in file_counts.keys():\n",
    "    file_df = ext_df[ext_df[\"file\"]==key]\n",
    "    output_path = os.path.join(output_dir, f'{key}.json')\n",
    "    collection_to_labelstudio(file_df, \"v172_geo_terms\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e14ba",
   "metadata": {},
   "source": [
    "**Note**: this notebook contains refactored code for data preparation, but the original input data this code was created for is no longer fully available (due to missing data sampling seed). Thus, the outcomes printed in this notebook do no correspond exactly to outputs of original data preparation notebooks (which are distributed elsewhere)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
